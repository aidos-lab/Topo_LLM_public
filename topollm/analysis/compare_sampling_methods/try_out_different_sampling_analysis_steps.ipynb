{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.filter_dataframe_based_on_filters_dict import (\n",
    "    filter_dataframe_based_on_filters_dict,\n",
    ")\n",
    "from topollm.analysis.compare_sampling_methods.load_and_concatenate_saved_dataframes import (\n",
    "    load_and_concatenate_saved_dataframes,\n",
    ")\n",
    "from topollm.analysis.compare_sampling_methods.make_plots import (\n",
    "    create_boxplot_of_mean_over_different_sampling_seeds,\n",
    "    generate_fixed_params_text,\n",
    ")\n",
    "from topollm.config_classes.constants import NAME_PREFIXES_TO_FULL_DESCRIPTIONS, TOPO_LLM_REPOSITORY_BASE_PATH\n",
    "from topollm.typing.enums import Verbosity\n",
    "\n",
    "# Create a logger\n",
    "default_logger: logging.Logger = logging.getLogger(name=__name__)\n",
    "default_logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Create a stream handler\n",
    "stream_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "stream_handler.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Create a formatter and attach it to the handler\n",
    "formatter = logging.Formatter(fmt=\"[%(asctime)s][%(levelname)8s][%(name)s] %(message)s (%(filename)s:%(lineno)s)\")\n",
    "stream_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "if not default_logger.handlers:  # Avoid adding duplicate handlers in case the cell is re-executed\n",
    "    default_logger.addHandler(hdlr=stream_handler)\n",
    "\n",
    "verbosity: Verbosity = Verbosity.NORMAL\n",
    "logger: logging.Logger = default_logger\n",
    "\n",
    "# Example usage\n",
    "logger.debug(msg=\"This is a debug message.\")\n",
    "logger.info(msg=\"This is an info message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_folder_base_path = pathlib.Path(\n",
    "    TOPO_LLM_REPOSITORY_BASE_PATH,\n",
    "    \"data/analysis/sample_sizes/\",\n",
    "    \"run_general_comparisons/\",\n",
    "    \"array_truncation_size=5000/\",\n",
    "    \"analysis/twonn/\",\n",
    ")\n",
    "\n",
    "concatenated_df: DataFrame = load_and_concatenate_saved_dataframes(\n",
    "    root_dir=comparisons_folder_base_path,\n",
    ")\n",
    "\n",
    "columns_to_investigate: list[str] = [\n",
    "    \"data_full\",\n",
    "    \"data_subsampling_full\",\n",
    "    \"model_partial_name\",\n",
    "]\n",
    "\n",
    "for column_name in columns_to_investigate:\n",
    "    logger.info(msg=30 * \"=\")\n",
    "    logger.info(\n",
    "        msg=f\"Unique values in column '{column_name = }':\",  # noqa: G004 - low overhead\n",
    "    )\n",
    "    logger.info(\n",
    "        msg=concatenated_df[column_name].unique(),\n",
    "    )\n",
    "\n",
    "concatenated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[\"model_full\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the influence of the data subsampling method on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.make_plots import (\n",
    "    Y_AXIS_LIMITS,\n",
    "    PlotSavePathCollection,\n",
    ")\n",
    "\n",
    "\n",
    "def log_unique_values(\n",
    "    filtered_concatenated_df: pd.DataFrame,\n",
    "    column_name: str = \"data_subsampling_number_of_samples\",\n",
    "    sampling_seed_column_name: str = \"data_subsampling_sampling_seed\",\n",
    "    verbosity: Verbosity = Verbosity.NORMAL,\n",
    "    logger: logging.Logger = default_logger,\n",
    ") -> None:\n",
    "    \"\"\"For every occurence of value in column_name, check how many rows are present in the filtered dataframe.\"\"\"\n",
    "    unique_values = filtered_concatenated_df[column_name].unique()\n",
    "\n",
    "    for unique_value in unique_values:\n",
    "        data_subsampling_number_of_samples_filters_dict = {\n",
    "            column_name: unique_value,\n",
    "        }\n",
    "\n",
    "        filtered_concatenated_df_for_unique_value: DataFrame = filter_dataframe_based_on_filters_dict(\n",
    "            df=filtered_concatenated_df,\n",
    "            filters_dict=data_subsampling_number_of_samples_filters_dict,\n",
    "        )\n",
    "\n",
    "        if verbosity >= Verbosity.NORMAL:\n",
    "            logger.info(\n",
    "                msg=f\"{unique_value = }: {filtered_concatenated_df_for_unique_value.shape = }\",  # noqa: G004 - low overhead\n",
    "            )\n",
    "\n",
    "    if verbosity >= Verbosity.NORMAL:\n",
    "        logger.info(\n",
    "            msg=f\"Unique {sampling_seed_column_name}:\\n{filtered_concatenated_df[sampling_seed_column_name].unique()}\",  # noqa: G004 - low overhead\n",
    "        )\n",
    "\n",
    "\n",
    "def create_histograms_over_data_subsampling_number_of_samples(\n",
    "    concatenated_df: pd.DataFrame,\n",
    "    concatenated_filters_dict: dict,\n",
    "    figsize: tuple[int, int] = (24, 8),\n",
    "    common_prefix_path: pathlib.Path | None = None,\n",
    "    verbosity: Verbosity = Verbosity.NORMAL,\n",
    "    logger: logging.Logger = default_logger,\n",
    ") -> None:\n",
    "    \"\"\"Create histograms over the data_subsampling_number_of_samples column.\"\"\"\n",
    "    filtered_concatenated_df: DataFrame = filter_dataframe_based_on_filters_dict(\n",
    "        df=concatenated_df,\n",
    "        filters_dict=concatenated_filters_dict,\n",
    "    )\n",
    "    if verbosity >= Verbosity.NORMAL:\n",
    "        logger.info(\n",
    "            msg=f\"{filtered_concatenated_df.shape = }\",  # noqa: G004 - low overhead\n",
    "        )\n",
    "\n",
    "    log_unique_values(\n",
    "        filtered_concatenated_df=filtered_concatenated_df,\n",
    "        column_name=\"data_subsampling_number_of_samples\",\n",
    "        sampling_seed_column_name=\"data_subsampling_sampling_seed\",\n",
    "        verbosity=verbosity,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # # # #\n",
    "    # Select the data for the analysis\n",
    "    data_for_different_data_subsampling_number_of_samples_analysis_df: DataFrame = filtered_concatenated_df\n",
    "\n",
    "    fixed_params_text: str = generate_fixed_params_text(\n",
    "        filters_dict=concatenated_filters_dict,\n",
    "    )\n",
    "\n",
    "    x_column_name = \"data_subsampling_number_of_samples\"\n",
    "\n",
    "    for y_min, y_max in Y_AXIS_LIMITS.values():\n",
    "        plot_save_path_collection: PlotSavePathCollection = PlotSavePathCollection.create_from_common_prefix_path(\n",
    "            common_prefix_path=common_prefix_path,\n",
    "            y_min=y_min,\n",
    "            y_max=y_max,\n",
    "        )\n",
    "\n",
    "        create_boxplot_of_mean_over_different_sampling_seeds(\n",
    "            subset_local_estimates_df=data_for_different_data_subsampling_number_of_samples_analysis_df,\n",
    "            plot_save_path_collection=plot_save_path_collection,\n",
    "            x_column_name=x_column_name,\n",
    "            y_column_name=\"array_data_truncated_mean\",\n",
    "            seed_column_name=\"data_subsampling_sampling_seed\",\n",
    "            fixed_params_text=fixed_params_text,\n",
    "            figsize=figsize,\n",
    "            y_min=y_min,\n",
    "            y_max=y_max,\n",
    "            verbosity=verbosity,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "\n",
    "def run_data_subsampling_number_of_samples_analysis(\n",
    "    data_full_list_to_process: list[str],\n",
    "    data_subsampling_split_list_to_process: list[str],\n",
    "    data_subsampling_sampling_mode_list_to_process: list[str],\n",
    "    model_full_list_to_process: list[str],\n",
    "    verbosity: Verbosity = Verbosity.NORMAL,\n",
    "    logger: logging.Logger = default_logger,\n",
    ") -> None:\n",
    "    \"\"\"Run the analysis over the different combinations of data, subsampling methods, and models.\"\"\"\n",
    "    product_to_process = product(\n",
    "        data_full_list_to_process,\n",
    "        data_subsampling_split_list_to_process,\n",
    "        data_subsampling_sampling_mode_list_to_process,\n",
    "        model_full_list_to_process,\n",
    "    )\n",
    "    product_to_process_list = list(product_to_process)\n",
    "\n",
    "    for (\n",
    "        data_full,\n",
    "        data_subsampling_split,\n",
    "        data_subsampling_sampling_mode,\n",
    "        model_full,\n",
    "    ) in tqdm(\n",
    "        iterable=product_to_process_list,\n",
    "        desc=\"Processing different combinations\",\n",
    "        total=len(product_to_process_list),\n",
    "    ):\n",
    "        concatenated_filters_dict = {\n",
    "            \"data_full\": data_full,\n",
    "            \"model_full\": model_full,\n",
    "            \"data_subsampling_split\": data_subsampling_split,\n",
    "            \"data_subsampling_sampling_mode\": data_subsampling_sampling_mode,\n",
    "            \"data_prep_sampling_method\": \"random\",\n",
    "            \"data_prep_sampling_samples\": 150_000,\n",
    "            NAME_PREFIXES_TO_FULL_DESCRIPTIONS[\"dedup\"]: \"array_deduplicator\",\n",
    "            \"local_estimates_samples\": 60_000,\n",
    "            \"n_neighbors\": 128,\n",
    "        }\n",
    "\n",
    "        common_prefix_path = pathlib.Path(\n",
    "            TOPO_LLM_REPOSITORY_BASE_PATH,\n",
    "            \"data\",\n",
    "            \"saved_plots\",\n",
    "            \"mean_estimates_over_different_data_subsampling_number_of_samples\",\n",
    "            f\"{data_full=}\",\n",
    "            f\"{data_subsampling_split=}\",\n",
    "            f\"{data_subsampling_sampling_mode=}\",\n",
    "            f\"{model_full=}\",\n",
    "        )\n",
    "\n",
    "        create_histograms_over_data_subsampling_number_of_samples(\n",
    "            concatenated_df=concatenated_df,\n",
    "            concatenated_filters_dict=concatenated_filters_dict,\n",
    "            figsize=(24, 8),\n",
    "            common_prefix_path=common_prefix_path,\n",
    "            verbosity=verbosity,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "\n",
    "run_data_subsampling_number_of_samples_analysis(\n",
    "    data_full_list_to_process=list(concatenated_df[\"data_full\"].unique()),\n",
    "    data_subsampling_split_list_to_process=list(concatenated_df[\"data_subsampling_split\"].unique()),\n",
    "    data_subsampling_sampling_mode_list_to_process=[\"random\"],\n",
    "    model_full_list_to_process=[\"model=roberta-base_task=masked_lm\"],\n",
    "    verbosity=verbosity,\n",
    "    logger=default_logger,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
