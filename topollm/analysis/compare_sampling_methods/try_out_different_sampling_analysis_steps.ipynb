{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting HYDRA_FULL_ERROR environment variable to '1'.\n",
      "os.environ['HYDRA_FULL_ERROR'] = '1'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.run_general_comparisons import (\n",
    "    load_and_concatenate_saved_dataframes,\n",
    ")\n",
    "from topollm.config_classes.constants import TOPO_LLM_REPOSITORY_BASE_PATH\n",
    "\n",
    "default_logger: logging.Logger = logging.getLogger(name=__name__)\n",
    "# Add stdout handler to default logger\n",
    "default_logger.addHandler(\n",
    "    hdlr=logging.StreamHandler(\n",
    "        stream=sys.stdout,\n",
    "    ),\n",
    ")\n",
    "\n",
    "logger: logging.Logger = default_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_folder_base_path = pathlib.Path(\n",
    "    TOPO_LLM_REPOSITORY_BASE_PATH,\n",
    "    \"data/analysis/sample_sizes/\",\n",
    "    \"run_general_comparisons/\",\n",
    "    \"array_truncation_size=5000/analysis/twonn/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2554 entries, 0 to 2553\n",
      "Data columns (total 38 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Unnamed: 0                          2554 non-null   int64  \n",
      " 1   path                                2554 non-null   object \n",
      " 2   array_name                          2554 non-null   object \n",
      " 3   array_data                          2554 non-null   object \n",
      " 4   data_prep_sampling_method           2554 non-null   object \n",
      " 5   data_prep_sampling_seed             2554 non-null   int64  \n",
      " 6   data_prep_sampling_samples          2554 non-null   int64  \n",
      " 7   local_estimates_desc_full           2554 non-null   object \n",
      " 8   local_estimates_description         2554 non-null   object \n",
      " 9   local_estimates_samples             2554 non-null   int64  \n",
      " 10  zerovec                             2554 non-null   object \n",
      " 11  deduplication                       2554 non-null   object \n",
      " 12  model_full                          2554 non-null   object \n",
      " 13  model_task                          2554 non-null   object \n",
      " 14  model_checkpoint                    2554 non-null   object \n",
      " 15  model_seed                          2554 non-null   object \n",
      " 16  model_partial_name                  2554 non-null   object \n",
      " 17  model_layer                         2554 non-null   int64  \n",
      " 18  aggregation                         2554 non-null   object \n",
      " 19  normalization                       2554 non-null   object \n",
      " 20  data_full                           1528 non-null   object \n",
      " 21  dataset_name                        1528 non-null   object \n",
      " 22  data_splitting_mode                 1528 non-null   object \n",
      " 23  context                             1528 non-null   object \n",
      " 24  feature_column                      1528 non-null   object \n",
      " 25  data_subsampling_full               2554 non-null   object \n",
      " 26  data_split                          2554 non-null   object \n",
      " 27  data_subsampling_number_of_samples  2554 non-null   int64  \n",
      " 28  data_subsampling_sampling_mode      2554 non-null   object \n",
      " 29  data_subsampling_sampling_seed      2554 non-null   object \n",
      " 30  n_neighbors_mode                    2554 non-null   object \n",
      " 31  n_neighbors                         2554 non-null   int64  \n",
      " 32  array_data.size                     2554 non-null   int64  \n",
      " 33  array_data_truncated                2554 non-null   object \n",
      " 34  array_data_mean                     2554 non-null   float64\n",
      " 35  array_data_std                      2554 non-null   float64\n",
      " 36  array_data_truncated_mean           2554 non-null   float64\n",
      " 37  array_data_truncated_std            2554 non-null   float64\n",
      "dtypes: float64(4), int64(8), object(26)\n",
      "memory usage: 758.3+ KB\n"
     ]
    }
   ],
   "source": [
    "concatenated_df: DataFrame = load_and_concatenate_saved_dataframes(\n",
    "    root_dir=comparisons_folder_base_path,\n",
    ")\n",
    "\n",
    "concatenated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Unique values in column 'column_name = 'data_full'':\n",
      "['data=multiwoz21_spl-mode=do_nothing_ctxt=dataset_entry_feat-col=ner_tags'\n",
      " nan]\n",
      "==============================\n",
      "Unique values in column 'column_name = 'data_subsampling_full'':\n",
      "['split=test_samples=2000_sampling=take_first'\n",
      " 'split=test_samples=6000_sampling=random_sampling'\n",
      " 'split=test_samples=10000_sampling=take_first'\n",
      " 'split=train_samples=10000_sampling=random_sampling'\n",
      " 'split=test_samples=8000_sampling=take_first'\n",
      " 'split=train_samples=8000_sampling=random_sampling'\n",
      " 'split=validation_samples=128_sampling=random_sampling'\n",
      " 'split=validation_samples=4000_sampling=take_first'\n",
      " 'split=test_samples=6000_sampling=take_first'\n",
      " 'split=test_samples=10000_sampling=random_sampling'\n",
      " 'split=train_samples=4000_sampling=random_sampling'\n",
      " 'split=validation_samples=6000_sampling=take_first'\n",
      " 'split=validation_samples=6000_sampling=random_sampling'\n",
      " 'split=validation_samples=10000_sampling=take_first'\n",
      " 'split=train_samples=2000_sampling=random_sampling'\n",
      " 'split=test_samples=4000_sampling=take_first'\n",
      " 'split=validation_samples=8000_sampling=take_first'\n",
      " 'split=validation_samples=2000_sampling=take_first'\n",
      " 'split=validation_samples=128_sampling=take_first'\n",
      " 'split=validation_samples=4000_sampling=random_sampling'\n",
      " 'split=validation_samples=10000_sampling=random_sampling'\n",
      " 'split=train_samples=6000_sampling=take_first'\n",
      " 'split=test_samples=8000_sampling=random_sampling'\n",
      " 'split=validation_samples=2000_sampling=random_sampling'\n",
      " 'split=train_samples=6000_sampling=random_sampling'\n",
      " 'split=train_samples=8000_sampling=take_first'\n",
      " 'split=train_samples=2000_sampling=take_first'\n",
      " 'split=test_samples=2000_sampling=random_sampling'\n",
      " 'split=train_samples=4000_sampling=take_first'\n",
      " 'split=validation_samples=8000_sampling=random_sampling'\n",
      " 'split=train_samples=10000_sampling=take_first'\n",
      " 'split=test_samples=4000_sampling=random_sampling']\n"
     ]
    }
   ],
   "source": [
    "columns_to_investigate = [\n",
    "    \"data_full\",\n",
    "    \"data_subsampling_full\",\n",
    "]\n",
    "\n",
    "for column_name in columns_to_investigate:\n",
    "    print(30 * \"=\")\n",
    "    print(\n",
    "        f\"Unique values in column '{column_name = }':\",\n",
    "    )\n",
    "    print(\n",
    "        concatenated_df[column_name].unique(),\n",
    "    )\n",
    "\n",
    "\n",
    "# TODO: For the reddit dataset, the string is not correctly parsed\n",
    "# TODO: In the random subsampling, the sampling-seed is not correctly parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the influence of the data subsampling method on the results\n",
    "\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.run_general_comparisons import filter_dataframe_based_on_filters_dict\n",
    "\n",
    "concatenated_filters_dict = {\n",
    "    \"data_full\": data_full,\n",
    "    \"data_prep_sampling_method\": \"random\",\n",
    "    \"deduplication\": \"array_deduplicator\",\n",
    "    \"model_partial_name\": model_partial_name,\n",
    "    \"n_neighbors\": 128,\n",
    "    \"data_prep_sampling_samples\": 100_000,\n",
    "    \"local_estimates_samples\": 60_000,\n",
    "}\n",
    "\n",
    "filtered_concatenated_df: DataFrame = filter_dataframe_based_on_filters_dict(\n",
    "    df=concatenated_df,\n",
    "    filters_dict=concatenated_filters_dict,\n",
    ")\n",
    "\n",
    "# TODO: Continue here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
