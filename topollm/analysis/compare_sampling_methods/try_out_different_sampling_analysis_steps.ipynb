{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.filter_dataframe_based_on_filters_dict import (\n",
    "    filter_dataframe_based_on_filters_dict,\n",
    ")\n",
    "from topollm.analysis.compare_sampling_methods.load_and_concatenate_saved_dataframes import (\n",
    "    load_and_concatenate_saved_dataframes,\n",
    ")\n",
    "from topollm.analysis.compare_sampling_methods.make_plots import (\n",
    "    create_boxplot_of_mean_over_different_sampling_seeds,\n",
    "    generate_fixed_params_text,\n",
    ")\n",
    "from topollm.config_classes.constants import NAME_PREFIXES_TO_FULL_DESCRIPTIONS, TOPO_LLM_REPOSITORY_BASE_PATH\n",
    "from topollm.typing.enums import Verbosity\n",
    "\n",
    "# Create a logger\n",
    "default_logger: logging.Logger = logging.getLogger(name=__name__)\n",
    "default_logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Create a stream handler\n",
    "stream_handler = logging.StreamHandler(stream=sys.stdout)\n",
    "stream_handler.setLevel(level=logging.DEBUG)\n",
    "\n",
    "# Create a formatter and attach it to the handler\n",
    "formatter = logging.Formatter(fmt=\"[%(asctime)s][%(levelname)8s][%(name)s] %(message)s (%(filename)s:%(lineno)s)\")\n",
    "stream_handler.setFormatter(fmt=formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "if not default_logger.handlers:  # Avoid adding duplicate handlers in case the cell is re-executed\n",
    "    default_logger.addHandler(hdlr=stream_handler)\n",
    "\n",
    "verbosity: Verbosity = Verbosity.NORMAL\n",
    "logger: logging.Logger = default_logger\n",
    "\n",
    "# Example usage\n",
    "logger.debug(msg=\"This is a debug message.\")\n",
    "logger.info(msg=\"This is an info message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons_folder_base_path = pathlib.Path(\n",
    "    TOPO_LLM_REPOSITORY_BASE_PATH,\n",
    "    \"data/analysis/sample_sizes/\",\n",
    "    \"run_general_comparisons/\",\n",
    "    \"array_truncation_size=5000/\",\n",
    "    \"analysis/twonn/\",\n",
    ")\n",
    "\n",
    "concatenated_df: DataFrame = load_and_concatenate_saved_dataframes(\n",
    "    root_dir=comparisons_folder_base_path,\n",
    ")\n",
    "\n",
    "columns_to_investigate: list[str] = [\n",
    "    \"data_full\",\n",
    "    \"data_subsampling_full\",\n",
    "    \"model_partial_name\",\n",
    "]\n",
    "\n",
    "for column_name in columns_to_investigate:\n",
    "    print(30 * \"=\")\n",
    "    print(\n",
    "        f\"Unique values in column '{column_name = }':\",\n",
    "    )\n",
    "    print(\n",
    "        concatenated_df[column_name].unique(),\n",
    "    )\n",
    "\n",
    "concatenated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df[\"model_full\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the influence of the data subsampling method on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.make_plots import Y_AXIS_LIMITS_ONLY_FULL\n",
    "\n",
    "\n",
    "def log_subsampling_number_of_samples_values(\n",
    "    filtered_concatenated_df: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"For every occurence of value in \"data_subsampling_number_of_samples\", check how many rows are present in the filtered dataframe.\"\"\"\n",
    "    data_subsampling_number_of_samples_values = filtered_concatenated_df[\"data_subsampling_number_of_samples\"].unique()\n",
    "\n",
    "    for data_subsampling_number_of_samples in data_subsampling_number_of_samples_values:\n",
    "        data_subsampling_number_of_samples_filters_dict = {\n",
    "            \"data_subsampling_number_of_samples\": data_subsampling_number_of_samples,\n",
    "        }\n",
    "\n",
    "        filtered_concatenated_df_for_number_of_samples: DataFrame = filter_dataframe_based_on_filters_dict(\n",
    "            df=filtered_concatenated_df,\n",
    "            filters_dict=data_subsampling_number_of_samples_filters_dict,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{data_subsampling_number_of_samples = }: {filtered_concatenated_df_for_number_of_samples.shape = }\",\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"Unique data_subsampling_sampling_seed:\\n\",\n",
    "        filtered_concatenated_df[\"data_subsampling_sampling_seed\"].unique(),\n",
    "    )\n",
    "\n",
    "\n",
    "def create_histograms_over_data_subsampling_number_of_samples(\n",
    "    concatenated_df: pd.DataFrame,\n",
    "    concatenated_filters_dict: dict,\n",
    "    figsize: tuple[int, int] = (24, 8),\n",
    "    common_prefix_path: pathlib.Path | None = None,\n",
    "    verbosity: Verbosity = Verbosity.NORMAL,\n",
    "    logger: logging.Logger = default_logger,\n",
    ") -> None:\n",
    "    filtered_concatenated_df: DataFrame = filter_dataframe_based_on_filters_dict(\n",
    "        df=concatenated_df,\n",
    "        filters_dict=concatenated_filters_dict,\n",
    "    )\n",
    "\n",
    "    log_subsampling_number_of_samples_values(\n",
    "        filtered_concatenated_df=filtered_concatenated_df,\n",
    "    )\n",
    "\n",
    "    print(f\"{filtered_concatenated_df.shape = }\")\n",
    "\n",
    "    # # # #\n",
    "    # START Additional data cleaning:\n",
    "    # Remove those samples where \"array_data.size\" is smaller than 30_000\n",
    "\n",
    "    filtered_concatenated_df_cleaned = filtered_concatenated_df[filtered_concatenated_df[\"array_data.size\"] >= 50_000]\n",
    "\n",
    "    # END Additional data cleaning\n",
    "    # # # #\n",
    "\n",
    "    data_for_different_data_subsampling_number_of_samples_analysis_df: DataFrame = filtered_concatenated_df_cleaned\n",
    "\n",
    "    fixed_params_text: str = generate_fixed_params_text(\n",
    "        filters_dict=concatenated_filters_dict,\n",
    "    )\n",
    "\n",
    "    x_column_name = \"data_subsampling_number_of_samples\"\n",
    "\n",
    "    for y_min, y_max in Y_AXIS_LIMITS_ONLY_FULL.values():\n",
    "        # TODO: Use the common prefix path\n",
    "\n",
    "        create_boxplot_of_mean_over_different_sampling_seeds(\n",
    "            subset_local_estimates_df=data_for_different_data_subsampling_number_of_samples_analysis_df,\n",
    "            plot_save_path=None,  # TODO: Select path\n",
    "            raw_data_save_path=None,  # TODO: Select path\n",
    "            aggregated_results_save_path=None,  # TODO: Select path\n",
    "            x_column_name=x_column_name,\n",
    "            y_column_name=\"array_data_truncated_mean\",\n",
    "            seed_column_name=\"data_subsampling_sampling_seed\",\n",
    "            fixed_params_text=fixed_params_text,\n",
    "            figsize=figsize,\n",
    "            y_min=y_min,\n",
    "            y_max=y_max,\n",
    "            verbosity=verbosity,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "\n",
    "def run_data_subsampling_number_of_samples_analysis(\n",
    "    data_full_list_to_process: list[str],\n",
    "    data_subsampling_split_list_to_process: list[str],\n",
    "    data_subsampling_sampling_mode_list_to_process: list[str],\n",
    "    model_full_list_to_process: list[str],\n",
    "    verbosity: Verbosity = Verbosity.NORMAL,\n",
    "    logger: logging.Logger = default_logger,\n",
    ") -> None:\n",
    "    product_to_process = product(\n",
    "        data_full_list_to_process,\n",
    "        data_subsampling_split_list_to_process,\n",
    "        data_subsampling_sampling_mode_list_to_process,\n",
    "        model_full_list_to_process,\n",
    "    )\n",
    "    product_to_process_list = list(product_to_process)\n",
    "\n",
    "    for (\n",
    "        data_full,\n",
    "        data_subsampling_split,\n",
    "        data_subsampling_sampling_mode,\n",
    "        model_full,\n",
    "    ) in tqdm(\n",
    "        iterable=product_to_process_list,\n",
    "        desc=\"Processing different combinations\",\n",
    "        total=len(product_to_process_list),\n",
    "    ):\n",
    "        concatenated_filters_dict = {\n",
    "            \"data_full\": data_full,\n",
    "            \"model_full\": model_full,\n",
    "            \"data_subsampling_split\": data_subsampling_split,\n",
    "            \"data_subsampling_sampling_mode\": data_subsampling_sampling_mode,\n",
    "            \"data_prep_sampling_method\": \"random\",\n",
    "            \"data_prep_sampling_samples\": 150_000,\n",
    "            NAME_PREFIXES_TO_FULL_DESCRIPTIONS[\"dedup\"]: \"array_deduplicator\",\n",
    "            \"local_estimates_samples\": 60_000,\n",
    "            \"n_neighbors\": 128,\n",
    "        }\n",
    "\n",
    "        common_prefix_path = pathlib.Path(\n",
    "            TOPO_LLM_REPOSITORY_BASE_PATH,\n",
    "            \"data\",\n",
    "            \"saved_plots\",\n",
    "            \"mean_estimates_over_different_data_subsampling_number_of_samples\",\n",
    "            f\"{data_full=}\",\n",
    "            f\"{data_subsampling_split=}\",\n",
    "            f\"{data_subsampling_sampling_mode=}\",\n",
    "            f\"{model_full=}\",\n",
    "        )\n",
    "\n",
    "        create_histograms_over_data_subsampling_number_of_samples(\n",
    "            concatenated_df=concatenated_df,\n",
    "            concatenated_filters_dict=concatenated_filters_dict,\n",
    "            figsize=(24, 8),\n",
    "            common_prefix_path=common_prefix_path,\n",
    "            verbosity=verbosity,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "\n",
    "# data_full = concatenated_df[\"data_full\"].unique()[1]\n",
    "# data_subsampling_split = concatenated_df[\"data_subsampling_split\"].unique()[1]\n",
    "# data_subsampling_sampling_mode_list_to_process: list[str] = [\"random\"]\n",
    "# data_subsampling_sampling_mode = data_subsampling_sampling_mode_list_to_process[0]\n",
    "# model_full = concatenated_df[\"model_full\"].unique()[0]\n",
    "\n",
    "run_data_subsampling_number_of_samples_analysis(\n",
    "    data_full_list_to_process=concatenated_df[\"data_full\"].unique(),\n",
    "    data_subsampling_split_list_to_process=concatenated_df[\"data_subsampling_split\"].unique(),\n",
    "    data_subsampling_sampling_mode_list_to_process=[\"random\"],\n",
    "    model_full_list_to_process=[\"model=roberta-base_task=masked_lm\"],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
