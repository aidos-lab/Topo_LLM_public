{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Currently skipped - Additional analysis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "from topollm.analysis.compare_sampling_methods.make_plots import Y_AXIS_LIMITS_ONLY_FULL\n",
    "\n",
    "\n",
    "def create_histograms_over_model_checkpoints(\n",
    "    concatenated_df: pd.DataFrame,\n",
    "    concatenated_filters_dict: dict,\n",
    "    plot_save_path: pathlib.Path | None = None,\n",
    "    raw_data_save_path: pathlib.Path | None = None,\n",
    ") -> None:\n",
    "    filtered_concatenated_df = filter_dataframe_based_on_filters_dict(\n",
    "        df=concatenated_df,\n",
    "        filters_dict=concatenated_filters_dict,\n",
    "    )\n",
    "\n",
    "    # # # #\n",
    "    # Filter for the dataframe with just the base model data\n",
    "\n",
    "    same_filters_but_for_base_model = concatenated_filters_dict.copy()\n",
    "    same_filters_but_for_base_model[\"model_partial_name\"] = \"model-roberta-base\"\n",
    "\n",
    "    filtered_for_base_model_concatenated_df = filter_dataframe_based_on_filters_dict(\n",
    "        df=concatenated_df,\n",
    "        filters_dict=same_filters_but_for_base_model,\n",
    "    )\n",
    "\n",
    "    # Set all the values in the \"model_checkpoint\" column to \"-1\"\n",
    "    filtered_for_base_model_concatenated_df[\"model_checkpoint\"] = -1\n",
    "\n",
    "    # # # #\n",
    "    # Create a dataframe by concatenating the two dataframes\n",
    "    data_for_checkpoint_analysis_df: DataFrame = pd.concat(\n",
    "        objs=[filtered_concatenated_df, filtered_for_base_model_concatenated_df],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # # # #\n",
    "    # Group \"data_for_checkpoint_analysis_df\" by value in 'model_checkpoint' column\n",
    "    # and make a boxplot of \"array_data_truncated_mean\" for each group\n",
    "\n",
    "    fixed_params_text: str = generate_fixed_params_text(\n",
    "        filters_dict=concatenated_filters_dict,\n",
    "    )\n",
    "\n",
    "    for y_min, y_max in Y_AXIS_LIMITS_ONLY_FULL.values():\n",
    "        # for y_min, y_max in [(6.0, 10.0)]:\n",
    "        create_boxplot_of_mean_over_different_sampling_seeds(\n",
    "            subset_local_estimates_df=data_for_checkpoint_analysis_df,\n",
    "            plot_save_path=plot_save_path,\n",
    "            raw_data_save_path=raw_data_save_path,\n",
    "            x_column_name=\"model_checkpoint\",\n",
    "            y_column_name=\"array_data_truncated_mean\",\n",
    "            fixed_params_text=fixed_params_text,\n",
    "            y_min=y_min,\n",
    "            y_max=y_max,\n",
    "            logger=logger,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "# NOTE: These names are currently not compatible with the current naming scheme\n",
    "\n",
    "data_full_list_to_process = [\n",
    "    \"data-multiwoz21_split-train_ctxt-dataset_entry_samples-10000_feat-col-ner_tags\",\n",
    "    \"data-multiwoz21_split-validation_ctxt-dataset_entry_samples-3000_feat-col-ner_tags\",\n",
    "    \"data-multiwoz21_split-test_ctxt-dataset_entry_samples-3000_feat-col-ner_tags\",\n",
    "    \"data-one-year-of-tsla-on-reddit_split-train_ctxt-dataset_entry_samples-10000_feat-col-ner_tags\",\n",
    "    \"data-one-year-of-tsla-on-reddit_split-validation_ctxt-dataset_entry_samples-3000_feat-col-ner_tags\",\n",
    "    \"data-one-year-of-tsla-on-reddit_split-test_ctxt-dataset_entry_samples-3000_feat-col-ner_tags\",\n",
    "]\n",
    "\n",
    "model_partial_name_list_to_process = [\n",
    "    \"model-model-roberta-base_task-masked_lm_multiwoz21-train-10000-ner_tags_ftm-standard_lora-None_5e-05-constant-0.01-50\",\n",
    "    # \"model-model-roberta-base_task-masked_lm_one-year-of-tsla-on-reddit-train-10000-ner_tags_ftm-standard_lora-None_5e-05-constant-0.01-50\",\n",
    "]\n",
    "\n",
    "for data_full, model_partial_name in product(data_full_list_to_process, model_partial_name_list_to_process):\n",
    "    concatenated_filters_dict = {\n",
    "        \"data_full\": data_full,\n",
    "        \"data_prep_sampling_method\": \"random\",\n",
    "        \"deduplication\": \"array_deduplicator\",\n",
    "        \"model_partial_name\": model_partial_name,\n",
    "        \"n_neighbors\": 128,\n",
    "        \"data_prep_sampling_samples\": 100_000,\n",
    "        \"local_estimates_samples\": 60_000,\n",
    "    }\n",
    "\n",
    "    create_histograms_over_model_checkpoints(\n",
    "        concatenated_df=concatenated_df,\n",
    "        concatenated_filters_dict=concatenated_filters_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "data_folder_list: list[str] = [\n",
    "    \"data-multiwoz21_split-train_ctxt-dataset_entry_samples-10000_feat-col-ner_tags/\",\n",
    "    \"data-multiwoz21_split-validation_ctxt-dataset_entry_samples-3000_feat-col-ner_tags/\",\n",
    "    \"data-multiwoz21_split-test_ctxt-dataset_entry_samples-3000_feat-col-ner_tags/\",\n",
    "    \"data-one-year-of-tsla-on-reddit_split-train_ctxt-dataset_entry_samples-10000_feat-col-ner_tags/\",\n",
    "    \"data-one-year-of-tsla-on-reddit_split-validation_ctxt-dataset_entry_samples-3000_feat-col-ner_tags/\",\n",
    "]\n",
    "\n",
    "model_folder_list: list[str] = [\n",
    "    \"model-roberta-base_task-masked_lm/\",\n",
    "]\n",
    "\n",
    "selected_data_folder = data_folder_list[4]\n",
    "selected_model_folder = model_folder_list[0]\n",
    "\n",
    "file_path = pathlib.Path(\n",
    "    comparisons_folder_base_path,\n",
    "    selected_data_folder,\n",
    "    \"lvl-token/add-prefix-space-True_max-len-512/\",\n",
    "    selected_model_folder,\n",
    "    \"layer--1_agg-mean/norm-None/\",\n",
    "    \"full_local_estimates_df.csv\",\n",
    ")\n",
    "\n",
    "results_base_directory_path: pathlib.Path = file_path.parent\n",
    "\n",
    "local_estimates_df: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=file_path,\n",
    ")\n",
    "\n",
    "# Select a subset of the data with the same parameters.\n",
    "# This allows comparing over different seeds.\n",
    "#\n",
    "# We do not fix the local_estimates_samples,\n",
    "# since we want to compare the results for different sample sizes.\n",
    "\n",
    "filters_dict = {\n",
    "    \"data_prep_sampling_method\": \"random\",\n",
    "    \"deduplication\": \"array_deduplicator\",\n",
    "    \"n_neighbors\": 128,\n",
    "    \"data_prep_sampling_samples\": 50000,\n",
    "}\n",
    "\n",
    "subset_local_estimates_df = filter_dataframe_based_on_filters_dict(df=local_estimates_df, filters_dict=filters_dict)\n",
    "\n",
    "subset_local_estimates_df.describe()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
