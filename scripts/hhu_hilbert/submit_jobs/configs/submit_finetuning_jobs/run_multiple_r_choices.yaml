defaults:
  - base_submit_finetuning_jobs_config
  - training_schedule:
    - long_constant_lr_scheduler
  - _self_

base_model:
  - roberta-base

finetuning_dataset:
  - train_and_eval_on_multiwoz21_10000_samples
  - train_and_eval_on_one-year-of-tsla-on-reddit

peft:
  - lora

gradient_modifier:
  - do_nothing

lora_r:
  - 4
  - 8
  - 16
  - 32
  - 64
  - 128
  - 256
  - 512

wandb_project: "Topo_LLM_run_multiple_r_choices"
