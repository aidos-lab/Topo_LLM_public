{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": ""
        },
        {
            "name": "Python Debugger: Current File with Arguments",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": "${command:pickArgs}"
        },
        {
            "name": "Python Debugger: Current File with Multirun",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--multirun",
                "data=sgd_test",
                "language_model=roberta-base,roberta-base_finetuned-on-multiwoz21_ftm-standard_full-dataset",
                "hydra.job.env_set.CUDA_VISIBLE_DEVICES=0",
                "tokenizer.add_prefix_space=True"
            ]
        },
        {
            "name": "Run pipeline - Local debugging - TwoNN; LUSTER with token masking; - Run pipeline.",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "--multirun",
                "hydra/sweeper=basic",
                "hydra/launcher=basic",
                "tokenizer.add_prefix_space=False",
                "data=luster",
                "data.column_name=source_target",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.split=validation",
                "language_model=gpt2",
                // "language_model=luster-full",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.token_masking.token_masking_mode=based_on_meta_column",
                "embeddings_data_prep.token_masking.token_mask_meta_column_name=mask_system_last",
                // "embeddings_data_prep.token_masking.token_mask_meta_column_name=mask_database,mask_state",
                // "embeddings_data_prep.token_masking.token_mask_meta_column_name=sentence_idx", // <- For debugging the token masking (since we do not have a filled column yet).
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates=twonn",
                "local_estimates.filtering.num_samples=500",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=128",
                "feature_flags.compute_and_store_embeddings.skip_compute_and_store_embeddings_in_pipeline=False",
            ],
            "env": {
                "PYTORCH_ENABLE_MPS_FALLBACK": "1"
            }
        },
    ]
}