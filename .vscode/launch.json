{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": ""
        },
        {
            "name": "Python Debugger: Current File with Arguments",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": "${command:pickArgs}"
        },
        {
            "name": "Python Debugger: Current File with Multirun",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "args": [
                "--multirun",
                "data=sgd_test",
                "language_model=roberta-base,roberta-base_finetuned-on-multiwoz21_ftm-standard_full-dataset",
                "hydra.job.env_set.CUDA_VISIBLE_DEVICES=0",
                "tokenizer.add_prefix_space=True",
            ]
        },
        {
            "name": "skip finetuning; only config file creation; run_finetune_language_model_on_huggingface_dataset.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/model_finetuning/run_finetune_language_model_on_huggingface_dataset.py",
            "console": "integratedTerminal",
            "args": [
                "feature_flags.finetuning.skip_finetuning=true",
                "feature_flags.finetuning.use_wandb=false",
            ]
        },
        {
            "name": "on NER task; run_finetune_language_model_on_huggingface_dataset.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/model_finetuning/run_finetune_language_model_on_huggingface_dataset.py",
            "console": "integratedTerminal",
            "args": [
                "finetuning=finetuning_for_token_classification",
                "finetuning.finetuning_datasets.train_dataset.data_subsampling.number_of_samples=100",
                "finetuning.finetuning_datasets.eval_dataset.data_subsampling.number_of_samples=20",
                "finetuning.eval_steps=2",
                "finetuning.trainer_modifier.mode=add_wandb_prediction_progress_callback",
                "finetuning.trainer_modifier.frequency=4",
                "feature_flags.wandb.use_wandb=false",
                "wandb.project=Topo_LLM_finetuning_for_token_classification_DEBUG",
            ]
        },
        {
            "name": "on MLM task; run_finetune_language_model_on_huggingface_dataset.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/model_finetuning/run_finetune_language_model_on_huggingface_dataset.py",
            "console": "integratedTerminal",
            "args": [
                "--multirun",
                "finetuning=finetuning_for_masked_lm",
                "finetuning.eval_steps=2",
                "finetuning.finetuning_datasets.train_dataset.data_subsampling.number_of_samples=80",
                "finetuning.finetuning_datasets.eval_dataset.data_subsampling.number_of_samples=20",
                "finetuning.num_train_epochs=2",
                "finetuning.trainer_modifier.mode=add_wandb_prediction_progress_callback",
                "finetuning.trainer_modifier.frequency=4",
                "finetuning.seed=1235,1236",
                "feature_flags.wandb.use_wandb=true",
                "wandb.project=Topo_LLM_finetuning_for_language_modeling_DEBUG",
            ]
        },
        {
            "name": "on CLM task; run_finetune_language_model_on_huggingface_dataset.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/model_finetuning/run_finetune_language_model_on_huggingface_dataset.py",
            "console": "integratedTerminal",
            "args": [
                "finetuning=finetuning_for_causal_lm",
                "finetuning.finetuning_datasets.train_dataset.data_subsampling.number_of_samples=100",
                "finetuning.finetuning_datasets.eval_dataset.data_subsampling.number_of_samples=20",
                "finetuning.eval_steps=2",
                "finetuning.trainer_modifier.mode=add_wandb_prediction_progress_callback",
                "finetuning.trainer_modifier.frequency=4",
                "feature_flags.wandb.use_wandb=false",
                "wandb.project=Topo_LLM_finetuning_for_language_modeling_DEBUG",
            ]
        },
        {
            "name": "run_local_estimates.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/local_estimates_computation/run_local_estimates.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // `add_prefix_space=True` is necessary to use the tokenizer with input split into words
                "data=multiwoz21",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                "data.data_subsampling.split=validation",
                "language_model=roberta-base",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=300",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "local_estimates.pointwise.relative_n_neighbors=0.3",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "Duplicate vectors test case - run_local_estimates.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/local_estimates_computation/run_local_estimates.py",
            "console": "integratedTerminal",
            // This prepared data leads to the `ValueError: Input X contains NaN.` error in `LinearRegression`.
            "args": [
                "tokenizer.add_prefix_space=True", // `add_prefix_space=True` is necessary to use the tokenizer with input split into words
                "data=multiwoz21",
                "data.number_of_samples=3000",
                "data.split=validation",
                "language_model=roberta-base",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=30000",
                "+embeddings_data_prep.sampling.sampling_mode=random",
                // "local_estimates.filtering.num_samples=2500",
                "local_estimates.filtering.num_samples=5000",
                // "local_estimates.filtering.deduplication_mode=identity",
                "local_estimates.filtering.deduplication_mode=array_deduplicator",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.relative_n_neighbors=0.3",
                // "local_estimates.pointwise.absolute_n_neighbors=64",
                "local_estimates.pointwise.absolute_n_neighbors=128",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=false"
            ]
        },
        {
            "name": "run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "data=multiwoz21",
                "data.number_of_samples=512",
                "data.split=validation",
                "language_model=roberta-base",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "+embeddings_data_prep.sampling.sampling_mode=random",
                // "+embeddings_data_prep.sampling.sampling_mode=take_first",
                "local_estimates.filtering.num_samples=500",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
            ]
        },
        {
            "name": "Regular Token Embedding; with POS on multiwoz21 - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                "data=multiwoz21",
                "data.number_of_samples=128",
                "data.split=validation",
                "language_model=roberta-base",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "+embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=300",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
            ]
        },
        {
            "name": "Regular Token Embedding; with POS, with data_subsampler - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                // "data=one-year-of-tsla-on-reddit_validation",
                // "data=one-year-of-tsla-on-reddit_test",
                "data=multiwoz21_validation",
                // "data=sgd_test",
                // "data.data_splitting.data_splitting_mode=proportions",
                // "data.data_splitting.split_shuffle=true",
                // "data.data_splitting.split_seed=123",
                // "data.data_split.split_seed=null", // 'null' in the Hydra config is mapped to `None` in the Python code, and then no seed is set for the split
                "data.data_subsampling.number_of_samples=128",
                // "data.data_subsampling.sampling_mode=take_first",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                // "data.data_subsampling.split=train",
                // "data.data_subsampling.split=validation",
                "language_model=roberta-base",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=300",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "Regular Token Embedding; with POS, with data_subsampler, with Gaussian noise - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                "data=multiwoz21",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                "data.data_subsampling.split=validation",
                "language_model=roberta-base",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=300",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "local_estimates.noise.artificial_noise_mode=gaussian",
                // "local_estimates.noise.artificial_noise_mode=do_nothing",
                "local_estimates.noise.distortion_parameter=0.001",
                "local_estimates.noise.seed=2",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "Masked Token Embedding; on multiwoz21, with POS, with data_subsampler - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                "data=multiwoz21_validation",
                "data.data_subsampling.split=validation",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=masked_token",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=1000",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "Masked Token Embedding; on reddit, with POS, with data_subsampler - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                "data=one-year-of-tsla-on-reddit", // Note: Since the sequences in the reddit dataset are quite long, this takes a long time to run in the masked token mode
                "data.data_subsampling.split=validation",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=masked_token",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=1000",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "Masked Token Embedding; on wikipedia, with POS, with data_subsampler - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                "data=wikitext-103-v1",
                "data.data_subsampling.split=validation",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=masked_token",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=1000",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "Regular Token Embedding; on wikipedia, with POS, with data_subsampler - run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/pipeline_scripts/run_pipeline_compute_embeddings_and_data_prep_and_local_estimate.py",
            "console": "integratedTerminal",
            "args": [
                "tokenizer.add_prefix_space=True", // This is necessary to use the tokenizer with input split into words
                "+data.dataset_type=huggingface_dataset_named_entity",
                "data=wikitext-103-v1",
                "data.data_subsampling.split=validation",
                "data.data_subsampling.number_of_samples=128",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.sampling_seed=777",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=regular",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=3000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "local_estimates.filtering.num_samples=1000",
                "local_estimates.compute_global_estimates=true",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.pointwise.absolute_n_neighbors=256",
                "feature_flags.analysis.create_plots_in_local_estimates_worker=true",
            ]
        },
        {
            "name": "run_single_setup_load_saved_perplexity_and_local_estimates_and_analyse.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/model_inference/perplexity/saved_perplexity_processing/run_single_setup_load_saved_perplexity_and_local_estimates_and_analyse.py",
            "console": "integratedTerminal",
            "args": [
                // "data=multiwoz21",
                "data=iclr_2024_submissions_test",
                // "language_model=roberta-base",
                "language_model=model-roberta-base_task-MASKED_LM_multiwoz21-train-10000-ner_tags_ftm-standard_lora-None_5e-05-linear-0.01-5",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=30000",
                "+embeddings_data_prep.sampling.sampling_mode=take_first",
            ]
        },
        {
            "name": "run_general_comparisons.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/compare_sampling_methods/run_general_comparisons.py",
            "console": "integratedTerminal",
            "args": []
        },
        {
            "name": "run_general_comparisons.py; without iteration",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/compare_sampling_methods/run_general_comparisons.py",
            "console": "integratedTerminal",
            "args": [
                "feature_flags.analysis.compare_sampling_methods.do_iterate_all_partial_search_base_directories=False",
            ]
        },
        {
            "name": "run_general_comparisons.py; without iteration; only noise analysis",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/compare_sampling_methods/run_general_comparisons.py",
            "console": "integratedTerminal",
            "args": [
                "feature_flags.analysis.compare_sampling_methods.do_iterate_all_partial_search_base_directories=False",
                "feature_flags.analysis.compare_sampling_methods.do_noise_analysis=True",
                "feature_flags.analysis.compare_sampling_methods.do_checkpoint_analysis=False",
                "feature_flags.analysis.compare_sampling_methods.do_data_subsampling_number_of_samples_analysis=False",
            ]
        },
        {
            "name": "run_general_comparisons.py; with iteration; but without expensive plots during iteration",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/compare_sampling_methods/run_general_comparisons.py",
            "console": "integratedTerminal",
            "args": [
                "feature_flags.analysis.compare_sampling_methods.do_iterate_all_partial_search_base_directories=True",
                "feature_flags.analysis.compare_sampling_methods.do_analysis_influence_of_local_estimates_n_neighbors=False",
                "feature_flags.analysis.compare_sampling_methods.do_create_boxplot_of_mean_over_different_sampling_seeds=False"
            ]
        },
        {
            "name": "run_compare_losses_and_local_estimates.py; on example multiwoz21 test data",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/investigate_distances_and_influence_on_local_estimates/run_compare_losses_and_local_estimates.py",
            "console": "integratedTerminal",
            "args": [
                "data=multiwoz21_test",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.number_of_samples=10000",
                "data.data_subsampling.sampling_seed=778",
                "+data.dataset_type=huggingface_dataset_named_entity",
                "tokenizer.add_prefix_space=True",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=masked_token",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=150000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "embeddings_data_prep.sampling.seed=42",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.filtering.deduplication_mode=array_deduplicator",
                "local_estimates.filtering.num_samples=60000",
                "local_estimates.pointwise.absolute_n_neighbors=128",
                // START: Comparison data.
                //
                // Note: We need to also set all the parameters we overwrote in the main data configuration,
                // since otherwise the comparison data configs will be initialized with the default values.
                //
                // << This is the same as in the main data configuration
                "+comparison_data.embeddings.embedding_data_handler.mode=masked_token",
                "+comparison_data.local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "+comparison_data.local_estimates.filtering.deduplication_mode=array_deduplicator",
                "+comparison_data.local_estimates.filtering.num_samples=60000",
                "+comparison_data.local_estimates.pointwise.absolute_n_neighbors=128",
                // << This is different from the main data configuration
                "+comparison_data.local_estimates.noise.artificial_noise_mode=gaussian",
                "+comparison_data.local_estimates.noise.distortion_parameter=0.01",
                "+comparison_data.local_estimates.noise.seed=4",
                // END: Comparison data.
                // "analysis.investigate_distances.array_truncation_size=500", // The value '500' can be used for quick testing
                // "analysis.investigate_distances.array_truncation_size=600",
                // "analysis.investigate_distances.array_truncation_size=5000",
                "analysis.investigate_distances.array_truncation_size=20000",
                "feature_flags.analysis.compare_sampling_methods.do_iterate_all_partial_search_base_directories=True", // This is an example for setting the feature flags
            ]
        },
        {
            "name": "run_compare_losses_and_local_estimates.py; on example wikitext test data",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/investigate_distances_and_influence_on_local_estimates/run_compare_losses_and_local_estimates.py",
            "console": "integratedTerminal",
            "args": [
                "data=wikitext-103-v1_test",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.number_of_samples=10000",
                "data.data_subsampling.sampling_seed=778",
                "+data.dataset_type=huggingface_dataset_named_entity",
                "tokenizer.add_prefix_space=True",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=masked_token",
                // Option: Take a different token mode for comparison
                "+comparison_data.embeddings.embedding_data_handler.mode=regular",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=150000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "embeddings_data_prep.sampling.seed=42",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.filtering.deduplication_mode=array_deduplicator",
                "local_estimates.filtering.num_samples=60000",
                "local_estimates.pointwise.absolute_n_neighbors=128",
                // "analysis.investigate_distances.array_truncation_size=500", // The value '500' can be used for quick testing
                // "analysis.investigate_distances.array_truncation_size=5000",
                "analysis.investigate_distances.array_truncation_size=20000",
                // Note: "analysis.investigate_distances.array_truncation_size=30000" runs out of memory on the 16GB MacBook Pro M1
                // "analysis.investigate_distances.array_truncation_size=60000", // The value '60000' potentially takes a long time to run, and this might run out of memory on the 16GB MacBook Pro M1
                "feature_flags.analysis.compare_sampling_methods.do_iterate_all_partial_search_base_directories=True", // This is an example for setting the feature flags
            ]
        },
        {
            "name": "run_iterate_over_twonn_results_and_compare_hausdorff_distances.py; on example directory",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/analysis/investigate_distances_and_influence_on_local_estimates/run_iterate_over_twonn_results_and_compare_hausdorff_distances.py",
            "console": "integratedTerminal",
            "args": [
                "--multirun",
                "data=multiwoz21_test",
                "data.data_subsampling.sampling_mode=random",
                "data.data_subsampling.number_of_samples=10000",
                "data.data_subsampling.sampling_seed=778,779",
                "+data.dataset_type=huggingface_dataset_named_entity",
                "tokenizer.add_prefix_space=True",
                "language_model=roberta-base",
                "embeddings.embedding_data_handler.mode=masked_token",
                "embeddings.embedding_extraction.layer_indices=[-1]",
                "embeddings_data_prep.sampling.num_samples=150000",
                "embeddings_data_prep.sampling.sampling_mode=random",
                "embeddings_data_prep.sampling.seed=42,43",
                "local_estimates.pointwise.n_neighbors_mode=absolute_size",
                "local_estimates.filtering.deduplication_mode=array_deduplicator",
                "local_estimates.filtering.num_samples=60000",
                "local_estimates.pointwise.absolute_n_neighbors=128",
                "analysis.investigate_distances.array_truncation_size=5000",
                "feature_flags.analysis.compare_sampling_methods.do_iterate_all_partial_search_base_directories=True", // This is an example for setting the feature flags
            ]
        },
        {
            "name": "gsutil_rsync_directory_to_and_from_gc_bucket.py",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/scripts/google_cloud/gsutil_rsync_directory_to_and_from_gc_bucket.py",
            "console": "integratedTerminal",
            "args": [
                "--source",
                "bucket",
                "--target",
                "local",
                "--subdirectory",
                "data/analysis/twonn",
                "hydra_output_dir",
                "--dry_run",
            ]
        },
        {
            "name": "call_submit_jobs_for_experiments_via_tmux_submission; local; multiple data lists",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/scripts/submission_scripts/call_submit_jobs_scripts/call_submit_jobs_for_experiments_via_tmux_submission.py",
            "console": "integratedTerminal",
            "args": [
                "--run-option",
                "dry_run",
                "--run-only-selected-configs-option",
                "run_all",
                // "run_single_random",
                "--submission-mode",
                "local",
                // >> Concrete experiment configurations
                // "--data-list-options",
                // "reddit_only",
                // "--data-list-options",
                // "multiwoz21_only",
                // "--data-list-options",
                // "wikitext_only"
            ]
        },
        {
            "name": "call_submit_jobs_for_experiments_via_tmux_submission; local; multiple layers for validation splits",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/scripts/submission_scripts/call_submit_jobs_scripts/call_submit_jobs_for_experiments_via_tmux_submission.py",
            "console": "integratedTerminal",
            "args": [
                // >>>> BEGIN: Select the run option
                // >>>> Use the following to dry run with all configurations
                // "--run-option",
                // "dry_run",
                // "--run-only-selected-configs-option",
                // "run_all",
                // >>>> Use the following to dry run a random configuration
                // "--run-option",
                // "dry_run",
                // "--run-only-selected-configs-option",
                // "run_single_random",
                // >>> Use the following to run a random configuration
                // "--run-option",
                // "do_submission",
                // "--run-only-selected-configs-option",
                // "run_single_random",
                // >>>> Use the following to run with all configurations
                "--run-option",
                "do_submission",
                "--run-only-selected-configs-option",
                "run_all",
                // >>>> END: Select the run option
                "--submission-mode",
                "local",
                // >> Concrete experiment configurations
                "--data-list-options",
                // "validation_split_only",
                // "multiwoz21_validation_and_reddit_validation",
                "iclr_validation_and_sgd_validation_and_wikitext_validation",
                "--experiment-selector-options",
                "regular_token_embeddings_multiple_layers_single_sample",
            ]
        },
        {
            "name": "call_submit_jobs_for_experiments_via_tmux_submission; local; multiple local neighborhood sizes for single data split",
            "type": "debugpy",
            "request": "launch",
            "program": "topollm/scripts/submission_scripts/call_submit_jobs_scripts/call_submit_jobs_for_experiments_via_tmux_submission.py",
            "console": "integratedTerminal",
            "args": [
                // >>>> BEGIN: Select the run option
                // >>>> Use the following to dry run with all configurations
                // "--run-option",
                // "dry_run",
                // "--run-only-selected-configs-option",
                // "run_all",
                // >>>> Use the following to dry run a random configuration
                // "--run-option",
                // "dry_run",
                // "--run-only-selected-configs-option",
                // "run_single_random",
                // >>> Use the following to run a random configuration
                // "--run-option",
                // "do_submission",
                // "--run-only-selected-configs-option",
                // "run_single_random",
                // >>>> Use the following to run with all configurations
                "--run-option",
                "do_submission",
                "--run-only-selected-configs-option",
                "run_all",
                // >>>> END: Select the run option
                "--submission-mode",
                "local",
                // >> Concrete experiment configurations
                "--experiment-stage",
                "skip_compute_embeddings_but_do_multiple_pipeline_runs",
                "--data-list-options",
                // "multiwoz21_validation_and_reddit_validation",
                "reddit_validation_only",
                // TODO: Potentially run this for another token subsample
                "--experiment-selector-options",
                "regular_token_embeddings_multiple_local_estimates_pointwise_absolute_n_neighbors",
            ]
        },
    ]
}