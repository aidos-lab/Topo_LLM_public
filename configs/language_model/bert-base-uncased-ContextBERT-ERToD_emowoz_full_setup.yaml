defaults:
  - tokenizer_modifier: bert
  - _self_

checkpoint_no: -100 # dummy value because we only have one checkpoint at the moment
seed: -100 # dummy value because we only have one seed at the moment
lm_mode: mlm
task_type: masked_lm
pretrained_model_name_or_path: ${paths.data_dir}/models/EmoLoop/ContextBERT_ERToD/extracted_bert_component/checkpoint-best
manual_tokenizer_override_pretrained_model_name_or_path: bert-base-uncased

short_model_name: bert-base-uncased-ContextBERT-ERToD_emowoz_full_setup_seed-${language_model.seed}_ckpt-${language_model.checkpoint_no}
