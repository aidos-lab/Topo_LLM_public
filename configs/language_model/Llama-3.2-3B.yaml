defaults:
  # Note: Since the Llama-3.2-3B model does not have a pad token set, it needs to be handled with a specific tokenizer modifier.
  - tokenizer_modifier: Llama-3
  - _self_

lm_mode: clm
task_type: causal_lm

pretrained_model_name_or_path: "meta-llama/Llama-3.2-3B"
short_model_name: "Llama-3.2-3B"