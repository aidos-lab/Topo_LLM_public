lm_mode: mlm
pretrained_model_name_or_path: bert-base-uncased
short_model_name: ${finetuning.base_model.pretrained_model_name_or_path}
task_type: masked_lm
tokenizer_modifier:
  mode: do_nothing
  padding_token: "[PAD]"