defaults:
  - base_model: roberta-base_for_token_classification
  - gradient_modifier: do_nothing
  - finetuning_datasets: train_and_eval_on_wnut_17
  - finetuning_parameters@_here_: default_parameters
  - ../tokenizer@tokenizer: basic_tokenizer
  - peft: standard
  - _self_

# NOTE:
# AssertionError: You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.
tokenizer:
  add_prefix_space: true

# TODO: Set the add_prefix_space flag to True (otherwise we cannot use the tokenizer)